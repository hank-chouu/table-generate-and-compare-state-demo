{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物件設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_preprocess(path):\n",
    "    # load input \n",
    "    input_state = []\n",
    "    if os.path.exists(path):\n",
    "        with open(path) as f:\n",
    "            for line in f.readlines():\n",
    "                input_state.append(line.strip('\\n'))\n",
    "    else:\n",
    "        print('Input path does not exist.')\n",
    "    # turn txt into a dict with correspond to columns in path table\n",
    "    labels = ['start', 'end']\n",
    "    content = list(map(lambda ele: int(ele), input_state[0:2]))\n",
    "    try:\n",
    "        for i in range(2, len(input_state), 2):    \n",
    "            labels.append('vehicle' + str(i//2 + 1))\n",
    "            content.append(int(input_state[i]))\n",
    "            labels.append('path' + str(i//2 + 1))\n",
    "            content.append(json.loads(input_state[i + 1]))\n",
    "        input_state = dict(zip(labels, content))\n",
    "        return input_state\n",
    "    \n",
    "    except ValueError:\n",
    "        raise ValueError('Incorrect input format.') \n",
    "\n",
    "def compare_paths(path1, path2):\n",
    "    # path1: from input, path2: from table\n",
    "    if not path1:\n",
    "        if not path2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if path2:\n",
    "\n",
    "            edges1 = set(zip(path1[:-1], path1[1:]))\n",
    "            edges2 = set(zip(path2[:-1], path2[1:]))\n",
    "            intersection = edges1.intersection(edges2)\n",
    "            # the similarity with comparison of path 1 \n",
    "            # set operations are comparing edges\n",
    "            # paths are in nodes, changed into edges by subtracting 1\n",
    "            score = len(intersection)/(len(path1)-1)\n",
    "\n",
    "            # penalty: the undesired edges in path2\n",
    "            # proportion to the edges in path1 and path2\n",
    "            diff = edges2.difference(intersection)\n",
    "            score -= len(diff)/(len(path2)-1)/(len(path1)-1)\n",
    "            return score\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "class State_Compare(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__full_table_list = None # became a list, for we need to read in chunks\n",
    "        self.__df_dtype = None\n",
    "        self.__preprocessed = None\n",
    "        self.__ncars = None\n",
    "        self.__input_state = None\n",
    "        self.__subset = None\n",
    "        self.__rows_high_score = None\n",
    "        self.__high_score_and_reward = None\n",
    "        \n",
    "    def read_table(self, path, output=False):\n",
    "        if os.path.exists(path):\n",
    "\n",
    "            chunk_size = 50000\n",
    "            df_list = []\n",
    "            if '.csv' in path:\n",
    "                with pd.read_csv(path, chunksize=chunk_size) as reader:\n",
    "                    for chunk in reader:\n",
    "                        df_list.append(chunk)\n",
    "                self.__full_table_list = df_list\n",
    "                self.__df_dtype = 'csv'\n",
    "            elif '.json' in path:\n",
    "                with pd.read_json(path, lines=True, orient='records', chunksize=chunk_size) as reader:\n",
    "                    for chunk in reader:\n",
    "                        df_list.append(chunk)\n",
    "                self.__full_table_list = df_list\n",
    "                self.__df_dtype = 'json'\n",
    "                self.__preprocessed = True\n",
    "            if output:\n",
    "                return pd.concat(df_list, ignore_index=True)\n",
    "        else:\n",
    "            print('Path Table does not exist')    \n",
    "\n",
    "    def set_ncars(self, ncars):\n",
    "        self.__ncars = ncars\n",
    "\n",
    "    def set_input(self, input_state):\n",
    "\n",
    "        self.__input_state = input_state\n",
    "        ncars = int((len(input_state)-2)/2 + 1)\n",
    "        self.set_ncars(ncars)\n",
    "    \n",
    "    def preprocess(self, output=False):   \n",
    "        if self.__preprocessed:\n",
    "            # this may occur if read in table is of type json\n",
    "            if output == True:\n",
    "                return pd.concat(self.__full_table_list, ignore_index=True)\n",
    "            return   \n",
    "        # this is to convert list as string into list\n",
    "        # if data is stroed as csv\n",
    "        if all(getattr(self, attr) is not None for attr in ['_State_Compare__full_table', '_State_Compare__ncars']):\n",
    "            ncars_table = int(len(self.__full_table_list[0].columns)/2)\n",
    "            if self.__ncars == ncars_table:\n",
    "                for chunk in self.__full_table_list:\n",
    "                    for i in range(2, self.__ncars*2, 2):\n",
    "                        chunk['path' + str(i//2 + 1)] = chunk.apply(lambda row: json.loads(row[i+1]), axis=1)\n",
    "                self.__preprocessed = True\n",
    "                if output == True:\n",
    "                    return pd.concat(self.__full_table_list, ignore_index=True)\n",
    "            else:\n",
    "                raise ValueError(''.join(['Ncars parameter is not aligned with columns in given table. Ncars: ', \n",
    "                                        str(self.__ncars), '. Ncars in table: ', str(ncars_table), '.']))\n",
    "        else:\n",
    "            raise AttributeError('Attributes is not defined. Run read_table() first.')\n",
    "        \n",
    "    def filter_start_end(self, output=False):\n",
    "\n",
    "        if all(getattr(self, attr) is not None for attr in ['_State_Compare__ncars', '_State_Compare__input_state', '_State_Compare__preprocessed']):\n",
    "            subset_list = []\n",
    "            for chunk in self.__full_table_list:\n",
    "                subset_list.append(chunk[(chunk.start == self.__input_state['start']) & (chunk.end == self.__input_state['end'])])\n",
    "\n",
    "            # by this step, it should not be necessary to read in chunks\n",
    "            self.__subset = pd.concat(subset_list, ignore_index=True)\n",
    "            if output:\n",
    "                return self.__subset\n",
    "        \n",
    "        else:\n",
    "            if self.__preprocessed is None:\n",
    "                raise AttributeError('Attribute preprocessed is not True. Run preprocess() first.')\n",
    "            else:\n",
    "                raise AttributeError('Attributes is not defined. Run set_input() and read_table() first.')\n",
    "\n",
    "    def path_most_similar(self, output=False):\n",
    "\n",
    "        # path has direction property\n",
    "        if all(getattr(self, attr) is not None for attr in ['_State_Compare__ncars', '_State_Compare__input_state', \n",
    "                                                            '_State_Compare__subset', '_State_Compare__preprocessed']):\n",
    "            \n",
    "           # cars to compare = ncars - 1\n",
    "            perm = permutations(range(0, self.__ncars-1))\n",
    "            perm_list = [list(p) for p in perm]\n",
    "            len_perm = len(perm_list)\n",
    "\n",
    "            path_cols  = []\n",
    "            score_cols = []\n",
    "            for i in range(1, self.__ncars):\n",
    "                path_cols.append('path' + str(i+1))\n",
    "                score_cols.append('path_score' + str(i))\n",
    "            subset_path = self.__subset[path_cols]\n",
    "            input_paths = [self.__input_state[key] for key in path_cols]\n",
    "\n",
    "            scores = pd.DataFrame(columns = score_cols.append('path_avg_score'))\n",
    "            for i in range(len_perm):\n",
    "                current_scores = pd.DataFrame(columns=score_cols)\n",
    "                for j in range(len(perm_list[i])):\n",
    "                    # for each permutation, compute a score of sum of each input path with correspond to table path\n",
    "                    current_scores['path_score' + str(j+1)] = subset_path.iloc[:, perm_list[i][j]].apply(lambda row: compare_paths(input_paths[j], row))\n",
    "                current_scores['path_avg_score'] = current_scores.mean(axis=1)\n",
    "                # extend the score df for each permutation\n",
    "                if scores.empty:\n",
    "                    scores = current_scores\n",
    "                else:\n",
    "                    scores = pd.concat([scores, current_scores])\n",
    "            \n",
    "            # find rows with max avg score in the score column\n",
    "            max_score = scores[scores['path_avg_score'] == scores['path_avg_score'].max()]\n",
    "            max_score = max_score.loc[max_score.index.unique()]\n",
    "            max_score_idx = list(max_score.index)\n",
    "            # find the correspond row in the original table\n",
    "            rows_high_score = self.__subset[self.__subset.index.isin(max_score_idx)]\n",
    "            rows_high_score = pd.concat([rows_high_score, max_score], axis=1)\n",
    "            self.__rows_high_score = rows_high_score\n",
    "\n",
    "            if output:\n",
    "                return self.__rows_high_score\n",
    "    \n",
    "        else:\n",
    "            if self.__preprocessed is None:\n",
    "                raise AttributeError('Attribute preprocessed is not True. Run preprocess() first.')\n",
    "            elif self.__subset is None:\n",
    "                raise AttributeError('Attribute subset is not defined. Run filter_start_end() first.')\n",
    "            else:\n",
    "                raise AttributeError('Attributes is not defined. Run set_input() and read_table() first.')\n",
    "            \n",
    "    def highest_reward(self, output=False):\n",
    "\n",
    "        if all(getattr(self, attr) is not None for attr in ['_State_Compare__rows_high_score']):\n",
    "\n",
    "            # find rows with highest reward frim last step\n",
    "            rows = self.__rows_high_score\n",
    "            highest_reward = rows[rows['reward'] == rows['reward'].max()]           \n",
    "\n",
    "            self.__high_score_and_reward = highest_reward\n",
    "\n",
    "            if output:\n",
    "                return self.__high_score_and_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用者介面\n",
    "\n",
    "## 讀取前面生成的表格資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare table file\n",
    "# execute time is mostly spent on reading in table\n",
    "table = State_Compare()\n",
    "table.read_table(path='state_path_reward.json')\n",
    "table.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取 input、拿 input 比對資料後找出 reward 最高的主機路徑（self_path）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>vehicle2</th>\n",
       "      <th>path2</th>\n",
       "      <th>vehicle3</th>\n",
       "      <th>path3</th>\n",
       "      <th>self_path</th>\n",
       "      <th>reward</th>\n",
       "      <th>path_score1</th>\n",
       "      <th>path_score2</th>\n",
       "      <th>path_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94567</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 6, 5, 2, 1]</td>\n",
       "      <td>7</td>\n",
       "      <td>[6, 5, 4, 7, 8, 9]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>0.92623</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.891667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start  end  vehicle2            path2  vehicle3               path3  \\\n",
       "94567      1    3         1  [3, 6, 5, 2, 1]         7  [6, 5, 4, 7, 8, 9]   \n",
       "\n",
       "       self_path   reward  path_score1  path_score2  path_avg_score  \n",
       "94567  [1, 2, 3]  0.92623     0.866667     0.916667        0.891667  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_state = input_preprocess('input.txt')\n",
    "table.set_input(input_state)\n",
    "# compare\n",
    "table.filter_start_end()\n",
    "table.path_most_similar()\n",
    "table.highest_reward(output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
